# Domashna_5

1. Data Ingestion Service (Сервис за собирање на податоци)
Цел: Овој сервис е одговорен за собирање на финансиски податоци од различни API сервиси (како Alpha Vantage или Yahoo Finance), нивно обработување и складирање во PostgreSQL база.

Користени технологии:
Python: Главен програмски јазик за креирање на сервисот.
FastAPI: За креирање на API за комуникација и давање на податоци преку HTTP.
PostgreSQL: За чување на податоците во релациона база на податоци.
Kafka: За пренос на податоците во реално време.
pandas: За обработка на податоците (на пример, форматирање на финансиски податоци).
Docker: За пакување на сервисот во контејнери, овозможувајќи лесно развојно и продукциско поставување на целиот систем.
Spark: Може да се користи за подетално обработување на податоци ако се додадат потреби за реално време.

Клучни делови на сервисот:
main.py: Главниот скрипт за стартување на FastAPI сервисот.
fetch_data.py: Комуникација со API-то за собирање на финансиски податоци.
kafka_producer.py: Изпраќање на податоци преку Kafka.
config.py: Конфигурации за API и Kafka.


2. Real-Time Data Processing Service (Сервис за обработка на податоци во реално време)

   
Цел: Овој сервис се користи за обработка на податоци кои се генерираат во реално време, пр користејќи Spark Streaming за обработка на податоците во реално време.

Користени технологии:
Apache Spark: Главен инструмент за обработка на големи податоци во реално време.
Spark Streaming: Модул за обработка на податоци во реално време.
Kafka: За примање и испраќање на податоци во реално време.
Docker: За пакување на сервисот во контејнери.
Java: Поради потребата за Spark, Java 11 е потребен за конфигурирање и покренување на Spark апликации.
Python: Користи Python скрипти за интеграција со Spark, обработка на податоци и покренување на Spark задачи.

Клучни делови на сервисот:
main.py: Главниот скрипт кој го стартува сервисот за обработка.
spark_processor.py: Скрипта која ја обработува стримувањето на податоците преку Spark.
config.py: Конфигурации за Spark и Kafka, кои ја дефинираат поврзаноста со базата, Kafka и други компоненти.
Кратка резиме за најважните технологии:
Docker: За пакување на двата сервиса во контејнери и овозможување на лесно конфигурирање, пренос и извршување.
Kafka: За пренос на податоци во реално време меѓу сервисите.
PostgreSQL: За складирање на податоците.
Spark: За обработка на големи количини податоци во реално време.
FastAPI: За креирање на API за комуникација со надворешни сервиси.
